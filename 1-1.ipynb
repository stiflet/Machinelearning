{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cddba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from config import Config\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from joblib import dump\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6428a0",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hf_dataset(name, *, split=None, cache_dir=None):\n",
    "    return load_dataset(name, split=split, cache_dir=cache_dir)\n",
    "\n",
    "\n",
    "def ensure_splits(dataset, *, config=None, seed=42):\n",
    "    if isinstance(dataset, DatasetDict):\n",
    "        if \"train\" in dataset and (\"test\" not in dataset or \"val\" not in dataset):\n",
    "            return ensure_splits(dataset[\"train\"], config=config, seed=seed)\n",
    "        return dataset\n",
    "\n",
    "    config = config or Config()\n",
    "    holdout = config.test_size + config.val_size\n",
    "\n",
    "    split = dataset.train_test_split(test_size=holdout, seed=seed)\n",
    "    if config.val_size <= 0:\n",
    "        return DatasetDict(train=split[\"train\"], test=split[\"test\"])\n",
    "\n",
    "    val_ratio = config.val_size / holdout\n",
    "    test_val = split[\"test\"].train_test_split(test_size=val_ratio, seed=seed)\n",
    "    return DatasetDict(train=split[\"train\"], val=test_val[\"test\"], test=test_val[\"train\"])\n",
    "\n",
    "\n",
    "def _image_to_array(image, *, resize=None, normalize=True):\n",
    "    if resize is not None:\n",
    "        image = image.resize(resize)\n",
    "    arr = np.asarray(image)\n",
    "    if arr.ndim == 2:\n",
    "        arr = np.stack([arr] * 3, axis=-1)\n",
    "    if normalize:\n",
    "        arr = arr.astype(\"float32\") / 255.0\n",
    "    return arr\n",
    "\n",
    "\n",
    "def _image_to_hog(image, *, resize=None, normalize=True, hog_params=None):\n",
    "    if resize is not None:\n",
    "        image = image.resize(resize)\n",
    "    if getattr(image, \"mode\", None) != \"L\":\n",
    "        image = image.convert(\"L\")\n",
    "    arr = np.asarray(image)\n",
    "    if normalize:\n",
    "        arr = arr.astype(\"float32\") / 255.0\n",
    "    return hog(arr, **hog_params)\n",
    "\n",
    "\n",
    "def flatten_images(\n",
    "    dataset,\n",
    "    *,\n",
    "    image_col=\"image\",\n",
    "    label_col=\"label\",\n",
    "    resize=None,\n",
    "    normalize=True,\n",
    "    data_format=\"flatten\",\n",
    "    hog_params=None,\n",
    "):\n",
    "    hog_params = hog_params or {\n",
    "        \"orientations\": 9,\n",
    "        \"pixels_per_cell\": (8, 8),\n",
    "        \"cells_per_block\": (2, 2),\n",
    "        \"block_norm\": \"L2-Hys\",\n",
    "    }\n",
    "    converters = {\n",
    "        \"flatten\": lambda img: _image_to_array(\n",
    "            img, resize=resize, normalize=normalize\n",
    "        ).reshape(-1),\n",
    "        \"hog\": lambda img: _image_to_hog(\n",
    "            img, resize=resize, normalize=normalize, hog_params=hog_params\n",
    "        ),\n",
    "    }\n",
    "    convert = converters[data_format]\n",
    "\n",
    "    def _prepare_batch(batch):\n",
    "        images = batch[image_col]\n",
    "        labels = batch[label_col]\n",
    "        features = [convert(img) for img in images]\n",
    "        return {\"features\": features, \"labels\": labels}\n",
    "\n",
    "    if isinstance(dataset, DatasetDict):\n",
    "        remove_columns = dataset[\"train\"].column_names\n",
    "        return dataset.map(_prepare_batch, batched=True, remove_columns=remove_columns)\n",
    "    return dataset.map(_prepare_batch, batched=True, remove_columns=dataset.column_names)\n",
    "\n",
    "\n",
    "def to_numpy(dataset, *, feature_col=\"features\", label_col=\"labels\"):\n",
    "    X = np.stack(dataset[feature_col])\n",
    "    y = np.asarray(dataset[label_col])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def prepare_for_classification(\n",
    "    name,\n",
    "    *,\n",
    "    image_col=\"image\",\n",
    "    label_col=\"label\",\n",
    "    resize=None,\n",
    "    normalize=None,\n",
    "    data_format=None,\n",
    "    hog_params=None,\n",
    "    config=None,\n",
    "    seed=42,\n",
    "):\n",
    "    dataset = ensure_splits(load_hf_dataset(name), config=config, seed=seed)\n",
    "    config = config or Config()\n",
    "    data_format = data_format or config.data_format\n",
    "    hog_params = hog_params or config.hog_params\n",
    "    if resize is None:\n",
    "        resize = config.image_size\n",
    "    if normalize is None:\n",
    "        normalize = config.normalize\n",
    "    dataset = flatten_images(\n",
    "        dataset,\n",
    "        image_col=image_col,\n",
    "        label_col=label_col,\n",
    "        resize=resize,\n",
    "        normalize=normalize,\n",
    "        data_format=data_format,\n",
    "        hog_params=hog_params,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a66630",
   "metadata": {},
   "source": [
    "## 1.1. Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bcddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(name=None, config=None):\n",
    "    config = config or Config()\n",
    "    ds = prepare_for_classification(name or config.dataset_name, config=config, seed=config.seed)\n",
    "    X_train, y_train = to_numpy(ds[\"train\"])\n",
    "    X_val, y_val = to_numpy(ds[\"val\"]) if \"val\" in ds else (None, None)\n",
    "    X_test, y_test = to_numpy(ds[\"test\"])\n",
    "    print(\"train:\", X_train.shape, y_train.shape)\n",
    "    if X_val is not None:\n",
    "        print(\"val:\", X_val.shape, y_val.shape)\n",
    "    print(\"test:\", X_test.shape, y_test.shape)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9434b",
   "metadata": {},
   "source": [
    "# 2. Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_svm(**kwargs):\n",
    "    return SVC(**kwargs)\n",
    "\n",
    "\n",
    "def build_random_forest(**kwargs):\n",
    "    return RandomForestClassifier(**kwargs)\n",
    "\n",
    "\n",
    "def build_boosting(**kwargs):\n",
    "    return GradientBoostingClassifier(**kwargs)\n",
    "\n",
    "\n",
    "def build_voting(\n",
    "    *,\n",
    "    svm_params,\n",
    "    random_forest_params,\n",
    "    voting=\"soft\",\n",
    "    weights=None,\n",
    "    **kwargs,\n",
    "):\n",
    "    svm_params = dict(svm_params)\n",
    "    if voting == \"soft\" and \"probability\" not in svm_params:\n",
    "        svm_params[\"probability\"] = True\n",
    "    svm_model = build_svm(**svm_params)\n",
    "    rf_model = build_random_forest(**random_forest_params)\n",
    "    return VotingClassifier(\n",
    "        estimators=[(\"svm\", svm_model), (\"random_forest\", rf_model)],\n",
    "        voting=voting,\n",
    "        weights=weights,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    return {\n",
    "        \"svm\": build_svm(),\n",
    "        \"random_forest\": build_random_forest(),\n",
    "        \"boosting\": build_boosting(),\n",
    "        \"voting\": build_voting(\n",
    "            svm_params=config.svm_params,\n",
    "            random_forest_params=config.random_forest_params,\n",
    "            voting=config.voting_params.get(\"voting\", \"soft\"),\n",
    "        ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2293e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _with_verbose(params, *, enabled, value):\n",
    "    if not enabled or \"verbose\" in params:\n",
    "        return params\n",
    "    return {**params, \"verbose\": value}\n",
    "\n",
    "\n",
    "def build_model(config, model_name):\n",
    "    builders = {\n",
    "        \"svm\": lambda: build_svm(\n",
    "            **_with_verbose(config.svm_params, enabled=config.training_verbose, value=True)\n",
    "        ),\n",
    "        \"random_forest\": lambda: build_random_forest(\n",
    "            **_with_verbose(config.random_forest_params, enabled=config.training_verbose, value=1)\n",
    "        ),\n",
    "        \"boosting\": lambda: build_boosting(\n",
    "            **_with_verbose(config.boosting_params, enabled=config.training_verbose, value=1)\n",
    "        ),\n",
    "        \"voting\": lambda: build_voting(\n",
    "            svm_params=config.svm_params,\n",
    "            random_forest_params=config.random_forest_params,\n",
    "            **_with_verbose(config.voting_params, enabled=config.training_verbose, value=1),\n",
    "        ),\n",
    "    }\n",
    "    return builders[model_name]()\n",
    "\n",
    "\n",
    "def train_and_eval(config=None):\n",
    "    config = config or Config()\n",
    "    print(\"loading data...\")\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = dataset(config=config)\n",
    "    print(\"data loaded\")\n",
    "    print(f\"train size: {X_train.shape[0]}\")\n",
    "    if X_val is not None:\n",
    "        print(f\"val size: {X_val.shape[0]}\")\n",
    "    print(f\"test size: {X_test.shape[0]}\")\n",
    "\n",
    "    model_list = config.model if isinstance(config.model, list) else [config.model]\n",
    "    trained = {}\n",
    "    val_scores = {}\n",
    "    total_models = len(model_list)\n",
    "    for idx, model_name in enumerate(model_list, start=1):\n",
    "        model = build_model(config, model_name)\n",
    "        print(f\"model {idx}/{total_models}: {model_name}\")\n",
    "        print(f\"model params ({model_name}): {model.get_params()}\")\n",
    "        print(f\"training starting ({model_name})...\")\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(\"training finished\")\n",
    "        print(f\"training time ({model_name}): {elapsed:.2f}s\")\n",
    "\n",
    "        if X_val is not None:\n",
    "            val_pred = model.predict(X_val)\n",
    "            val_acc = accuracy_score(y_val, val_pred)\n",
    "            val_scores[model_name] = val_acc\n",
    "            print(\"val accuracy:\", val_acc)\n",
    "\n",
    "        model_path = f\"model_{model_name}.pth\"\n",
    "        dump(model, model_path)\n",
    "        print(f\"model saved: {model_path}\")\n",
    "        trained[model_name] = model\n",
    "\n",
    "    if X_val is not None and val_scores:\n",
    "        best_model_name = max(val_scores, key=val_scores.get)\n",
    "        print(f\"best model by val accuracy: {best_model_name} ({val_scores[best_model_name]:.4f})\")\n",
    "    else:\n",
    "        best_model_name = model_list[0]\n",
    "        print(\"no validation set available; evaluating test on first model only\")\n",
    "\n",
    "    best_model = trained[best_model_name]\n",
    "    print(f\"evaluating test set ({best_model_name})...\")\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    print(\"test accuracy:\", accuracy_score(y_test, test_pred))\n",
    "    print(classification_report(y_test, test_pred))\n",
    "\n",
    "    return trained"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "princessml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
